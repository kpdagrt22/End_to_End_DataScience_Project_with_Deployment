# End-to-End ML Project with MLOps | Modular, Trackable, and Deployable

<p align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/9/93/Amazon_Web_Services_Logo.svg" alt="AWS" height="40"/>
  <img src="https://github.com/apache/airflow/blob/main/airflow-core/docs/img/logos/wordmark_1.svg?raw=true" alt="Airflow" height="40"/>
  <img src="https://avatars.githubusercontent.com/u/41825161?s=200&v=4" alt="DVC" height="40"/>
  <img src="https://github.com/mlflow/mlflow/blob/master/assets/logo.svg?raw=true" alt="MLflow" height="40"/>
  <img src="https://upload.wikimedia.org/wikipedia/commons/4/4e/Docker_%28container_engine%29_logo.svg" alt="Docker" height="40"/>
  <img src="https://commons.wikimedia.org/wiki/File:FastAPI_logo.svg#/media/File:FastAPI_logo.svg" alt="FastAPI" height="40"/>
  <img src="https://logowik.com/content/uploads/images/grafana3182.jpg" alt="Grafana" height="40"/>
</p>

## üöÄ Project Overview
This project demonstrates a **complete, production-ready data science workflow** implemented using **modular design principles**. It covers every stage of the ML lifecycle ‚Äî from **data ingestion** to **model evaluation and tracking** ‚Äî and adheres to **industry best practices** for configuration, pipeline orchestration, and experiment management.

---

## üìå Features
- **Modular architecture** using Python packages and custom components
- **Version-controlled datasets and models** via DVC and Git
- **ML pipeline orchestration** using Apache Airflow & Astronomer
- **Experiment tracking** with MLflow
- **Deployment-ready app** using FastAPI
- **Monitoring with Grafana dashboards**
- **Config and schema management** with YAML
- **Automated folder and logging setup**

---

## üß± Project Architecture
```
project-root/
‚îÇ
‚îú‚îÄ‚îÄ config/                  # YAML-based config files
‚îú‚îÄ‚îÄ constants/              # Hard-coded values and constants
‚îú‚îÄ‚îÄ entity/                 # Data classes for type safety
‚îú‚îÄ‚îÄ components/             # Core ML pipeline components
‚îÇ   ‚îú‚îÄ‚îÄ data_ingestion.py
‚îÇ   ‚îú‚îÄ‚îÄ data_transformation.py
‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.py
‚îÇ   ‚îî‚îÄ‚îÄ model_evaluation.py
‚îÇ
‚îú‚îÄ‚îÄ pipeline/               # Training and prediction pipelines
‚îÇ
‚îú‚îÄ‚îÄ utils/                  # Common reusable functions
‚îÇ
‚îú‚îÄ‚îÄ logs/                   # Central logging location
‚îú‚îÄ‚îÄ templates/              # Flask/FastAPI HTML templates (for app)
‚îú‚îÄ‚îÄ Dockerfile              # Containerization setup
‚îú‚îÄ‚îÄ requirements.txt        # Dependencies
‚îú‚îÄ‚îÄ setup.py                # For packaging
‚îú‚îÄ‚îÄ main.py                 # Trigger pipeline execution
‚îî‚îÄ‚îÄ README.md
```

---

## ‚öôÔ∏è Technologies Used
- **Languages & Libraries**: Python, Scikit-learn, Pandas, Matplotlib, YAML, Joblib
- **MLOps & Workflow**: MLflow, DVC, Apache Airflow, Astronomer
- **Deployment**: Docker, FastAPI
- **Cloud**: AWS EC2, S3
- **Monitoring**: Grafana
- **Utilities**: ConfigBox, Ensure Annotation, Logging, GitHub Actions

---

## üß™ ML Lifecycle
1. **Data Ingestion**: Reads zipped data from GitHub, unzips & stores in `artifacts`
2. **Data Validation**: Validates schema using YAML
3. **Data Transformation**: Cleans and prepares features
4. **Model Training**: Trains a RandomForest model, logs with MLflow
5. **Model Evaluation**: Compares metrics, selects best model
6. **Deployment**: Docker + FastAPI endpoint ready for inference
7. **Monitoring**: Metrics tracked using MLflow UI and Grafana dashboards

---

## üìÅ Configuration Strategy
All runtime parameters (e.g., file paths, model settings, schema) are defined in:
- `config.yaml`
- `params.yaml`
- `schema.yaml`

These are read using `ConfigBox` for dot-access and type safety.

---

## üß∞ How to Run
```bash
# Step 1: Create Conda environment
conda create -p venv python=3.10 -y
conda activate ./venv

# Step 2: Install dependencies
pip install -r requirements.txt

# Step 3: Set up and run project
python template.py     # auto-generates folder structure
python main.py         # runs the training pipeline

# Step 4: Track experiment
mlflow ui              # opens MLflow dashboard

# Optional: Deploy with Docker
docker build -t mlproject .
docker run -p 8080:8080 mlproject
```

---

## üë®‚Äçüíª Author
**Prakash Kantumutchu**  
AI/ML Engineer | 7.5+ Yrs Experience  
[GitHub](https://github.com/kpdagrt22) | [LinkedIn](https://linkedin.com/in/prakash-kantumutchu)  

---

## üìå Certifications Related to This Project
- AI Agent Developer ‚Äî Vanderbilt University
- Azure AI Engineer Associate (AI-102)
- Machine Learning Scientist with Python ‚Äî DataCamp
- Docker Foundations, GitHub Actions Pro

---

## üåü Highlights
- Designed for real-world, production environments
- Covers both **MLOps** and **modular software engineering**
- Showcases **YAML-based automation**, **logging**, and **versioning**
- Ideal template for interviews, demos, and enterprise workflows

> **"Built with the same mindset used in production teams ‚Äî scalable, testable, and deployable."**

---



*Coming Soon in repo images folder...*

---

## ‚≠ê Give a Star
If this repo helped you understand real-world DS pipelines, consider starring it!

